# -*- coding: utf-8 -*-
"""TrabalhoML final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18abdgj31Wbti2jEFdb48Xfxy40JWkGJl

**DATASET CLASSIFICAÇÃO**: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset/data <br>
"""

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OrdinalEncoder
import pandas as pd
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt
import joblib as jb

dataset = pd.read_csv('healthcare-dataset-stroke-data.csv')

dataset.head()

dataset['stroke'].value_counts()

dataset.isnull().sum()

# remove as linhas com IMC nulo
dataset = dataset.dropna(subset=['bmi'])

# transformar valores de IMC em faixas numéricas de acordo com tabela acima
dataset.loc[(dataset['bmi'] < 18.5), 'bmi_cat'] = 1
dataset.loc[(dataset['bmi'] >= 18.5) & (dataset['bmi'] < 25), 'bmi_cat'] = 2
dataset.loc[(dataset['bmi'] >= 25) & (dataset['bmi'] < 30), 'bmi_cat'] = 3
dataset.loc[(dataset['bmi'] >= 30), 'bmi_cat'] = 4

dataset['bmi_cat'] = dataset['bmi_cat'].astype('int')
dataset['bmi_cat'].value_counts()

# De acordo com a literarura médica os níveis de glicose seguem essa classificação:
# Normal: avg_glucose_level < 100
# Pré-diabetes: 100 ≤ avg_glucose_level < 126
# Diabetes: avg_glucose_level ≥ 126
# transformar valores de IMC em faixas numéricas de acordo com tabela acima
dataset.loc[(dataset['avg_glucose_level'] < 100), 'avg_glucose_level_cat'] = 1
dataset.loc[(dataset['avg_glucose_level'] >= 100) & (dataset['avg_glucose_level'] < 126), 'avg_glucose_level_cat'] = 2
dataset.loc[(dataset['avg_glucose_level'] >= 126), 'avg_glucose_level_cat'] = 3

dataset['avg_glucose_level_cat'] = dataset['avg_glucose_level_cat'].astype('int')
dataset['avg_glucose_level_cat'].value_counts()

dataset.drop('id', axis=1, inplace=True)
dataset.drop('bmi', axis=1, inplace=True)
dataset.drop('avg_glucose_level', axis=1, inplace=True)

dataset.info()

columns = dataset.select_dtypes(include=['object']).columns
columns

ordinal = OrdinalEncoder()

values_cat = ordinal.fit_transform(dataset[columns])
dataset[columns] = values_cat

dataset.head()

# Separando as classes
class_0 = dataset[dataset['stroke'] == 0]
class_1 = dataset[dataset['stroke'] == 1]

# Balanceando o dataset - Subamostrando a classe maior
if len(class_0) > len(class_1):
    class_0_balanced = class_0.sample(len(class_1), random_state=42)
    balanced_data = pd.concat([class_0_balanced, class_1], axis=0)
else:
    class_1_balanced = class_1.sample(len(class_0), random_state=42)
    balanced_data = pd.concat([class_0, class_1_balanced], axis=0)

# Embaralhar os dados para evitar qualquer ordem específica
balanced_dataset = shuffle(balanced_data, random_state=42)

# Separando novamente em features (x_balanced) e labels (y_balanced)
x_balanced = balanced_dataset.drop(columns=['stroke']).values
y_balanced = balanced_dataset['stroke'].values

# Conferindo o balanceamento
print("Distribuição após balanceamento:")
print(pd.Series(y_balanced).value_counts())

x = balanced_dataset.drop('stroke', axis=1)
y = balanced_dataset['stroke']

# Separar a coluna idade para normalizar
idade = balanced_dataset['age']
scaler_idade = MinMaxScaler()
idade_scaled = scaler_idade.fit_transform(idade.values.reshape(-1, 1))

# reunir os dados novamente
balanced_dataset['age'] = idade_scaled

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

balanced_dataset.head()

"""utilizando GridSearch CV"""

# knn
knn_params = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}
knn = KNeighborsClassifier()

grid_search_knn = GridSearchCV(knn, knn_params, cv=5, scoring='accuracy')
grid_search_knn.fit(x_train, y_train)

# arvore de decisão
dt_params = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
dt = DecisionTreeClassifier()

grid_search_dt = GridSearchCV(dt, dt_params, cv=5, scoring='accuracy')
grid_search_dt.fit(x_train, y_train)

# floresta randomica
rf_params = {
    'n_estimators': [50, 100, 150],  # Número de árvores na floresta
    'max_depth': [10, 20, 30],  # Profundidade máxima das árvores
    'min_samples_split': [2, 5, 10],  # Número mínimo de amostras necessárias para dividir um nó
    'class_weight': ['balanced', None]  # Ajuste de pesos para lidar com classes desbalanceadas
}

rf = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)

grid_search_rf = GridSearchCV(estimator=rf, param_grid=rf_params, cv=5, scoring='accuracy', n_jobs=-1)

grid_search_rf.fit(x_train, y_train)


# Logistic Regression
lr_params = {
   'C': [0.01, 0.1, 1, 10, 100],
    'solver': ['liblinear', 'saga'],
    'max_iter': [100, 200, 300]
}

lr = LogisticRegression(random_state=42, n_jobs=-1)

grid_search_lr = GridSearchCV(estimator=lr, param_grid=lr_params, cv=5, scoring='accuracy', n_jobs=-1)

grid_search_lr.fit(x_train, y_train)

print("Melhores hiperparâmetros para KNN:", grid_search_knn.best_params_)
print("Acurácia do KNN:", grid_search_knn.best_score_)

print("Melhores hiperparâmetros para Árvore de Decisão:", grid_search_dt.best_params_)
print("Acurácia da Árvore de Decisão:", grid_search_dt.best_score_)

print("Melhores hiperparâmetros para Random Forest:", grid_search_rf.best_params_)
print("Acurácia do Random Forest:", grid_search_rf.best_score_)

print("Melhores hiperparâmetros para Regressão Logística:", grid_search_lr.best_params_)
print("Acurácia da Regressão Logística:", grid_search_lr.best_score_)

y_pred_knn = grid_search_knn.best_estimator_.predict(x_test)

y_pred_dt = grid_search_dt.best_estimator_.predict(x_test)

y_pred_rf = grid_search_rf.best_estimator_.predict(x_test)

y_pred_lr = grid_search_lr.best_estimator_.predict(x_test)

# Avaliação do KNN otimizado
y_pred_knn = grid_search_knn.best_estimator_.predict(x_test)
print("Relatório de Classificação para KNN:")
print(classification_report(y_test, y_pred_knn))
print("Acurácia do KNN:", accuracy_score(y_test, y_pred_knn))
print("Precisão do KNN:", precision_score(y_test, y_pred_knn))
print("Recall do KNN:", recall_score(y_test, y_pred_knn))
print("F1-score do KNN:", f1_score(y_test, y_pred_knn))
print("Matriz de Confusão para KNN:")
print(confusion_matrix(y_test, y_pred_knn))

# Avaliação da arvore de decisao otimizada
y_pred_dt = grid_search_dt.best_estimator_.predict(x_test)
print("Relatório de Classificação para Árvore de Decisão:")
print(classification_report(y_test, y_pred_dt))
print("Acurácia da Árvore de Decisão:", accuracy_score(y_test, y_pred_dt))
print("Precisão da Árvore de Decisão:", precision_score(y_test, y_pred_dt))
print("Recall da Árvore de Decisão:", recall_score(y_test, y_pred_dt))
print("F1-score da Árvore de Decisão:", f1_score(y_test, y_pred_dt))
print("Matriz de Confusão para Árvore de Decisão:")
print(confusion_matrix(y_test, y_pred_dt))

# Avaliação do Random Forest otimizado
y_pred_rf = grid_search_rf.best_estimator_.predict(x_test)
print("Relatório de Classificação para Random Forest:")
print(classification_report(y_test, y_pred_rf))
print("Acurácia do Random Forest:", accuracy_score(y_test, y_pred_rf))
print("Precisão do Random Forest:", precision_score(y_test, y_pred_rf))
print("Recall do Random Forest:", recall_score(y_test, y_pred_rf))
print("F1-score do Random Forest:", f1_score(y_test, y_pred_rf))
print("Matriz de Confusão para Random Forest:")
print(confusion_matrix(y_test, y_pred_rf))

# Avaliação da Regressão Logística otimizada
y_pred_lr = grid_search_lr.best_estimator_.predict(x_test)
print("Relatório de Classificação para Regressão Logística:")
print(classification_report(y_test, y_pred_lr))
print("Acurácia da Regressão Logística:", accuracy_score(y_test, y_pred_lr))
print("Precisão da Regressão Logística:", precision_score(y_test, y_pred_lr))
print("Recall da Regressão Logística:", recall_score(y_test, y_pred_lr))
print("F1-score da Regressão Logística:", f1_score(y_test, y_pred_lr))
print("Matriz de Confusão para Regressão Logística:")
print(confusion_matrix(y_test, y_pred_lr))

correlation_matrix = dataset.corr()

plt.figure(figsize=(10, 8))

sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)

plt.title("Mapa de Calor - Correlação Dataset", fontsize=16)
plt.xticks(rotation=45)
plt.yticks(rotation=0)

plt.show()

# Calcular a matriz de correlação
correlation_matrix_balanced = balanced_dataset.corr()

# Configurar o tamanho da figura
plt.figure(figsize=(10, 8))

# Criar o mapa de calor
sns.heatmap(correlation_matrix_balanced, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)

# Títulos e rótulos
plt.title("Mapa de Calor - Correlação Dataset Balanceado", fontsize=16)
plt.xticks(rotation=45)
plt.yticks(rotation=0)

# Exibir o gráfico
plt.show()

stroke_correlation = correlation_matrix['stroke'].sort_values(ascending=False)
stroke_correlation_bal = correlation_matrix_balanced['stroke'].sort_values(ascending=False)

print(stroke_correlation)
print(stroke_correlation_bal)

best_model = None
best_score = 0

if grid_search_knn.best_score_ > best_score:
    best_model = grid_search_knn.best_estimator_
    best_score = grid_search_knn.best_score_

if grid_search_dt.best_score_ > best_score:
    best_model = grid_search_dt.best_estimator_
    best_score = grid_search_dt.best_score_

if grid_search_rf.best_score_ > best_score:
    best_model = grid_search_rf.best_estimator_
    best_score = grid_search_rf.best_score_

if grid_search_lr.best_score_ > best_score:
    best_model = grid_search_lr.best_estimator_
    best_score = grid_search_lr.best_score_

print(f"Melhor modelo: {best_model}")
print(f"Melhor acurácia: {best_score}")

jb.dump(best_model, 'random_forest_model.pkl')
jb.dump(ordinal, 'ordinal_encoder.pkl')
jb.dump(scaler_idade, 'scaler_idade.pkl')

print("Modelo e pré-processadores salvos com sucesso!")